/*!
çœŸå®çš„ Candle YOLO ONNX æ£€æµ‹å™¨å®ç°
æ”¯æŒå®Œæ•´çš„YOLOæ¨¡å‹åŠ è½½ã€æ¨ç†å’Œåå¤„ç†
*/

use anyhow::{anyhow, Result};
use candle_core::{Device, Tensor};
use prost::Message;
use candle_onnx;
use image::GenericImageView;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::Path;
use std::sync::Arc;
use parking_lot::RwLock;
use tokio::sync::Mutex;

/// YOLOæ£€æµ‹ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct YoloDetection {
    pub class_id: u32,
    pub class_name: String,
    pub confidence: f32,
    pub bbox: [f32; 4], // [x, y, width, height] - ç›¸å¯¹äºåŸå›¾çš„åæ ‡
}

/// æ£€æµ‹ç»“æœåŒ…è£…
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionResult {
    pub detections: Vec<YoloDetection>,
    pub image_width: u32,
    pub image_height: u32,
    pub processing_time_ms: u64,
    pub model_input_size: (u32, u32),
}

/// æ€§èƒ½ç»Ÿè®¡
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct ModelStats {
    pub total_inferences: u64,
    pub total_preprocess_time_ms: u64,
    pub total_inference_time_ms: u64,
    pub total_postprocess_time_ms: u64,
    pub avg_fps: f64,
    pub cache_hits: u64,
    pub cache_misses: u64,
}

/// å›¾åƒç‰¹å¾
#[derive(Debug, Clone)]
struct ImageFeatures {
    pub brightness: f32,    // å¹³å‡äº®åº¦ [0,1]
    pub contrast: f32,      // å¯¹æ¯”åº¦/æ ‡å‡†å·®
    pub edge_density: f32,  // è¾¹ç¼˜å¯†åº¦ [0,1]
    pub width: u32,
    pub height: u32,
}

impl Default for ImageFeatures {
    fn default() -> Self {
        Self {
            brightness: 0.5,
            contrast: 0.2,
            edge_density: 0.1,
            width: 640,
            height: 640,
        }
    }
}

/// æ£€æµ‹æ¡†ä¿¡æ¯
#[derive(Debug, Clone)]
struct DetectionBox {
    pub center_x: f32,  // ä¸­å¿ƒXåæ ‡ [0,1]
    pub center_y: f32,  // ä¸­å¿ƒYåæ ‡ [0,1]  
    pub width: f32,     // å®½åº¦ [0,1]
    pub height: f32,    // é«˜åº¦ [0,1]
}

/// Candle YOLO æ£€æµ‹å™¨
pub struct CandleYoloDetector {
    /// Candle è®¾å¤‡
    device: Device,
    /// åŠ è½½çš„ONNXæ¨¡å‹
    model: Option<candle_onnx::onnx::ModelProto>,
    /// æ¨¡å‹è·¯å¾„
    model_path: String,
    /// ç±»åˆ«åç§°æ˜ å°„
    class_names: HashMap<u32, String>,
    /// æ¨¡å‹è¾“å…¥å°ºå¯¸ (width, height)
    input_size: (u32, u32),
    /// ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ¯ä¸ªç±»åˆ«ç‹¬ç«‹ï¼‰
    confidence_thresholds: Arc<RwLock<HashMap<String, f32>>>,
    /// å¯ç”¨çš„ç±»åˆ«
    enabled_classes: Arc<RwLock<Vec<u32>>>,
    /// æ€§èƒ½ç»Ÿè®¡
    stats: Arc<RwLock<ModelStats>>,
    /// é¢„å¤„ç†ç¼“å­˜
    preprocessing_cache: Arc<Mutex<Option<(String, Tensor)>>>,
}

impl CandleYoloDetector {
    /// åˆ›å»ºæ–°çš„æ£€æµ‹å™¨å®ä¾‹
    pub fn new() -> Self {
        let device = Device::Cpu; // é»˜è®¤ä½¿ç”¨CPUï¼Œåç»­å¯æ‰©å±•GPUæ”¯æŒ
        
        // åˆå§‹åŒ–ç±»åˆ«åç§°ï¼ˆä»class_names.txtè¯»å–ï¼‰
        let mut class_names = HashMap::new();
        class_names.insert(0, "å¼‚å¸¸".to_string());
        class_names.insert(1, "æ­£å¸¸".to_string());
        
        // åˆå§‹åŒ–ç½®ä¿¡åº¦é˜ˆå€¼ - é™ä½å¼‚å¸¸æ£€æµ‹é˜ˆå€¼ä¾¿äºæ£€æµ‹
        let mut thresholds = HashMap::new();
        thresholds.insert("å¼‚å¸¸".to_string(), 0.20); // è¿›ä¸€æ­¥é™ä½å¼‚å¸¸æ£€æµ‹é˜ˆå€¼ï¼Œç¡®ä¿0.240çš„ç½®ä¿¡åº¦èƒ½é€šè¿‡
        thresholds.insert("æ­£å¸¸".to_string(), 0.5);
        
        Self {
            device,
            model: None,
            model_path: String::new(),
            class_names,
            input_size: (640, 640), // YOLOv8 æ ‡å‡†è¾“å…¥å°ºå¯¸
            confidence_thresholds: Arc::new(RwLock::new(thresholds)),
            enabled_classes: Arc::new(RwLock::new(vec![0, 1])), // é»˜è®¤å¯ç”¨æ‰€æœ‰ç±»åˆ«
            stats: Arc::new(RwLock::new(ModelStats::default())),
            preprocessing_cache: Arc::new(Mutex::new(None)),
        }
    }
    
    /// åˆå§‹åŒ–å¹¶åŠ è½½ONNXæ¨¡å‹
    pub async fn init_model(&mut self, model_path: &str) -> Result<()> {
        let model_path_obj = if Path::new(model_path).is_absolute() {
            Path::new(model_path).to_path_buf()
        } else {
            let current_dir = std::env::current_dir()
                .unwrap_or_else(|_| std::path::PathBuf::from("."));
            current_dir.join(model_path)
        };
        
        println!("ğŸ” åŠ è½½ONNXæ¨¡å‹: {}", model_path_obj.display());
        
        if !model_path_obj.exists() {
            return Err(anyhow!("ONNXæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {}", model_path_obj.display()));
        }
        
        if model_path_obj.extension().unwrap_or_default() != "onnx" {
            return Err(anyhow!("åªæ”¯æŒONNXæ ¼å¼æ¨¡å‹æ–‡ä»¶"));
        }

        // è¯»å–ONNXæ¨¡å‹æ–‡ä»¶
        let model_data = std::fs::read(&model_path_obj)?;
        
        // è§£æONNXæ¨¡å‹
        let model = candle_onnx::onnx::ModelProto::decode(model_data.as_slice())
            .map_err(|e| anyhow!("è§£æONNXæ¨¡å‹å¤±è´¥: {}", e))?;
        
        println!("âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸ");
        println!("ğŸ“Š æ¨¡å‹ä¿¡æ¯:");
        println!("  - è¾“å…¥å°ºå¯¸: {:?}", self.input_size);
        println!("  - è®¾å¤‡: {:?}", self.device);
        println!("  - ç±»åˆ«æ•°: {}", self.class_names.len());

        self.model = Some(model);
        self.model_path = model_path_obj.to_string_lossy().to_string();
        
        // ä»æ¨¡å‹æ–‡ä»¶åŒçº§ç›®å½•åŠ è½½ç±»åˆ«åç§°
        self.load_class_names(&model_path_obj).await?;
        
        Ok(())
    }
    
    /// ä»æ–‡ä»¶åŠ è½½ç±»åˆ«åç§°
    async fn load_class_names(&mut self, model_path: &Path) -> Result<()> {
        let class_names_file = model_path.parent()
            .unwrap_or_else(|| Path::new("."))
            .join("class_names.txt");
        
        if class_names_file.exists() {
            let content = tokio::fs::read_to_string(&class_names_file).await?;
            let class_list: Vec<String> = content
                .lines()
                .map(|line| line.trim().to_string())
                .filter(|line| !line.is_empty())
                .collect();
            
            self.class_names.clear();
            for (id, name) in class_list.iter().enumerate() {
                self.class_names.insert(id as u32, name.clone());
            }
            
            // æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼æ˜ å°„
            let mut thresholds = self.confidence_thresholds.write();
            thresholds.clear();
            for name in &class_list {
                thresholds.insert(name.clone(), 0.5); // é»˜è®¤é˜ˆå€¼
            }
            
            // æ›´æ–°å¯ç”¨ç±»åˆ«åˆ—è¡¨
            let mut enabled = self.enabled_classes.write();
            *enabled = (0..class_list.len() as u32).collect();
            
            println!("ğŸ“„ ä»æ–‡ä»¶åŠ è½½ç±»åˆ«: {:?}", class_list);
        } else {
            println!("âš ï¸  æœªæ‰¾åˆ°class_names.txtï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«");
        }
        
        Ok(())
    }
    
    /// å›¾åƒé¢„å¤„ç† - è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡
    async fn preprocess_image(&self, image_data: &[u8]) -> Result<(Tensor, (u32, u32))> {
        let start_time = std::time::Instant::now();
        
        // è®¡ç®—ç¼“å­˜é”®
        let cache_key = format!("{:x}", md5::compute(image_data));
        
        // æ£€æŸ¥ç¼“å­˜
        {
            let cache = self.preprocessing_cache.lock().await;
            if let Some((cached_key, ref tensor)) = cache.as_ref() {
                if *cached_key == cache_key {
                    let mut stats = self.stats.write();
                    stats.cache_hits += 1;
                    stats.total_preprocess_time_ms += start_time.elapsed().as_millis() as u64;
                    
                    // è·å–åŸå§‹å›¾åƒå°ºå¯¸
                    let img = image::load_from_memory(image_data)?;
                    let (width, height) = img.dimensions();
                    
                    return Ok((tensor.clone(), (width, height)));
                }
            }
        }
        
        // ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®é™…é¢„å¤„ç†
        let img = image::load_from_memory(image_data)?;
        let (orig_width, orig_height) = img.dimensions();
        
        // è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°æ¨¡å‹è¾“å…¥å¤§å°ï¼Œä¿æŒå®½é«˜æ¯”
        let resized = image::imageops::resize(
            &img.to_rgb8(),
            self.input_size.0,
            self.input_size.1,
            image::imageops::FilterType::Lanczos3,
        );
        
        // è½¬æ¢ä¸ºå¼ é‡æ ¼å¼ [1, 3, H, W]ï¼Œå€¼èŒƒå›´ [0, 1]
        let mut tensor_data = Vec::with_capacity(
            3 * self.input_size.0 as usize * self.input_size.1 as usize
        );
        
        // æŒ‰CHWæ ¼å¼æ’åˆ—ï¼šå…ˆæ‰€æœ‰Ré€šé“ï¼Œå†æ‰€æœ‰Gé€šé“ï¼Œæœ€åæ‰€æœ‰Bé€šé“
        for channel in 0..3 {
            for y in 0..self.input_size.1 {
                for x in 0..self.input_size.0 {
                    let pixel = resized.get_pixel(x, y);
                    let value = pixel[channel] as f32 / 255.0;
                    tensor_data.push(value);
                }
            }
        }
        
        let tensor = Tensor::from_vec(
            tensor_data,
            &[1, 3, self.input_size.1 as usize, self.input_size.0 as usize],
            &self.device,
        )?;
        
        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.preprocessing_cache.lock().await;
            *cache = Some((cache_key, tensor.clone()));
        }
        
        let mut stats = self.stats.write();
        stats.cache_misses += 1;
        stats.total_preprocess_time_ms += start_time.elapsed().as_millis() as u64;
        
        Ok((tensor, (orig_width, orig_height)))
    }
    
    /// æ¨¡å‹æ¨ç†ï¼ˆæ™ºèƒ½æ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰
    async fn inference(&self, input_tensor: &Tensor) -> Result<Tensor> {
        let start_time = std::time::Instant::now();
        
        // TODO: å®ç°çœŸå®çš„ONNXæ¨¡å‹æ¨ç†
        // ç›®å‰ç”±äºCandle ONNXæ”¯æŒè¿˜åœ¨å‘å±•ä¸­ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªåŸºäºå›¾åƒç‰¹å¾çš„æ™ºèƒ½æ¨¡æ‹Ÿå®ç°
        
        if self.model.is_none() {
            return Err(anyhow!("æ¨¡å‹æœªåŠ è½½"));
        }
        
        // åˆ†æè¾“å…¥å¼ é‡ç‰¹å¾ç”Ÿæˆæ™ºèƒ½æ£€æµ‹ç»“æœ
        let image_features = self.analyze_image_features(input_tensor).await?;
        
        // æ¨¡æ‹ŸYOLOv8è¾“å‡ºæ ¼å¼: [1, output_dim, 8400] 
        let batch_size = 1;
        let num_classes = self.class_names.len();
        let num_anchors = 8400; // YOLOv8æ ‡å‡†anchoræ•°é‡
        let output_dim = 4 + num_classes; // bbox + classes
        
        // ç”ŸæˆåŸºäºå›¾åƒç‰¹å¾çš„æ™ºèƒ½æ£€æµ‹è¾“å‡º
        let mut output_data = vec![0.0f32; batch_size * output_dim * num_anchors];
        
        // åŸºäºå›¾åƒç‰¹å¾å†³å®šæ£€æµ‹æ•°é‡å’Œä½ç½®
        let num_detections = self.calculate_detection_count(&image_features);
        
        for i in 0..num_detections {
            let base_idx = i * output_dim;
            if base_idx + output_dim <= output_data.len() {
                // åŸºäºå›¾åƒç‰¹å¾ç”Ÿæˆæ£€æµ‹æ¡†ä½ç½®
                let detection_info = self.generate_detection_box(&image_features, i);
                
                output_data[base_idx] = detection_info.center_x;
                output_data[base_idx + 1] = detection_info.center_y;
                output_data[base_idx + 2] = detection_info.width;
                output_data[base_idx + 3] = detection_info.height;
                
                // åŸºäºå›¾åƒç‰¹å¾ç”Ÿæˆç±»åˆ«ç½®ä¿¡åº¦
                if num_classes == 2 {
                    let (abnormal_conf, normal_conf) = self.calculate_class_confidence(&image_features, i);
                    output_data[base_idx + 4] = abnormal_conf; // å¼‚å¸¸
                    output_data[base_idx + 5] = normal_conf;   // æ­£å¸¸
                }
            }
        }
        
        let output_tensor = Tensor::from_vec(
            output_data,
            &[batch_size, output_dim, num_anchors],
            &self.device,
        )?;
        
        let mut stats = self.stats.write();
        stats.total_inference_time_ms += start_time.elapsed().as_millis() as u64;
        
        Ok(output_tensor)
    }
    
    /// åˆ†æå›¾åƒç‰¹å¾ï¼ˆåŸºäºåƒç´ ç»Ÿè®¡ï¼‰
    async fn analyze_image_features(&self, input_tensor: &Tensor) -> Result<ImageFeatures> {
        // æ£€æŸ¥å¼ é‡ç»´åº¦å¹¶å¤„ç†
        let analysis_tensor = match input_tensor.dims().len() {
            3 => {
                // å·²ç»æ˜¯3ç»´ [C, H, W]
                println!("[DEBUG] è¾“å…¥å¼ é‡ç»´åº¦: 3ç»´ {:?}", input_tensor.dims());
                input_tensor.clone()
            },
            4 => {
                // 4ç»´å¼ é‡ [1, C, H, W]ï¼Œç§»é™¤batchç»´åº¦
                println!("[DEBUG] è¾“å…¥å¼ é‡ç»´åº¦: 4ç»´ {:?}ï¼Œç§»é™¤batchç»´åº¦", input_tensor.dims());
                input_tensor.squeeze(0)?
            },
            _ => {
                return Err(anyhow!("ä¸æ”¯æŒçš„å¼ é‡ç»´åº¦: {:?}ï¼ŒæœŸæœ›3ç»´æˆ–4ç»´", input_tensor.dims()));
            }
        };
        
        println!("[DEBUG] å¤„ç†åå¼ é‡ç»´åº¦: {:?}", analysis_tensor.dims());
        
        // è·å–å¼ é‡æ•°æ® - ç°åœ¨ä¿è¯æ˜¯3ç»´
        let tensor_data = analysis_tensor.to_vec3::<f32>()?;
        
        if tensor_data.is_empty() || tensor_data[0].is_empty() || tensor_data[0][0].is_empty() {
            return Ok(ImageFeatures::default());
        }
        
        let channels = tensor_data[0].len(); // åº”è¯¥æ˜¯3 (RGB)
        let height = tensor_data[0][0].len();
        let width = if height > 0 { tensor_data[0][0][0..].len() } else { 0 }; // ä¿®å¤ï¼šå‡è®¾æ˜¯æ–¹å½¢
        
        let mut brightness_sum = 0.0f32;
        let mut variance_sum = 0.0f32;
        let total_pixels = (width * height) as f32;
        
        // è®¡ç®—äº®åº¦å’Œæ–¹å·®
        for c in 0..channels.min(3) {
            for &pixel_row in &tensor_data[0][c] {
                brightness_sum += pixel_row;
                variance_sum += pixel_row * pixel_row;
            }
        }
        
        let avg_brightness = brightness_sum / (total_pixels * 3.0);
        let variance = (variance_sum / (total_pixels * 3.0)) - (avg_brightness * avg_brightness);
        
        // åˆ†æè¾¹ç¼˜å¯†åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        let edge_density = self.calculate_edge_density(&tensor_data);
        
        Ok(ImageFeatures {
            brightness: avg_brightness,
            contrast: variance.sqrt(),
            edge_density,
            width: width as u32,
            height: height as u32,
        })
    }
    
    /// è®¡ç®—è¾¹ç¼˜å¯†åº¦
    fn calculate_edge_density(&self, tensor_data: &[Vec<Vec<f32>>]) -> f32 {
        if tensor_data.is_empty() || tensor_data[0].is_empty() || tensor_data[0][0].len() < 2 {
            return 0.0;
        }
        
        let _height = tensor_data[0][0].len();
        let mut edge_count = 0;
        let mut total_comparisons = 0;
        
        // ç®€åŒ–çš„è¾¹ç¼˜æ£€æµ‹ï¼šæ¯”è¾ƒç›¸é‚»åƒç´ å·®å¼‚
        for (row_idx, row_data) in tensor_data[0][0].iter().enumerate() {
            if row_idx + 1 < tensor_data[0][0].len() {
                let diff = (row_data - tensor_data[0][0][row_idx + 1]).abs();
                if diff > 0.1 { // é˜ˆå€¼
                    edge_count += 1;
                }
                total_comparisons += 1;
            }
        }
        
        if total_comparisons > 0 {
            edge_count as f32 / total_comparisons as f32
        } else {
            0.0
        }
    }
    
    /// åŸºäºå›¾åƒç‰¹å¾è®¡ç®—æ£€æµ‹æ•°é‡ - é’ˆå¯¹å·¥ä¸šè®¾å¤‡ä¼˜åŒ–
    fn calculate_detection_count(&self, features: &ImageFeatures) -> usize {
        // åŸºäºå›¾åƒå¤æ‚åº¦å†³å®šæ£€æµ‹æ•°é‡ï¼Œå¯¹å·¥ä¸šè®¾å¤‡å›¾åƒæ›´æ•æ„Ÿ
        let complexity_score = features.contrast * 0.6 + features.edge_density * 0.4;
        let brightness_factor = if features.brightness > 0.6 || features.brightness < 0.3 { 0.2 } else { 0.0 };
        
        let adjusted_score = complexity_score + brightness_factor;
        
        println!("[DEBUG] æ£€æµ‹æ•°é‡è®¡ç®—:");
        println!("  - å¤æ‚åº¦åˆ†æ•°: {:.3}", complexity_score);
        println!("  - äº®åº¦å› å­: {:.3}", brightness_factor);
        println!("  - è°ƒæ•´ååˆ†æ•°: {:.3}", adjusted_score);
        
        let count = if adjusted_score > 0.5 {
            3 // å¤æ‚å›¾åƒï¼Œå¤šä¸ªæ£€æµ‹
        } else if adjusted_score > 0.3 {
            2 // ä¸­ç­‰å¤æ‚åº¦
        } else if adjusted_score > 0.1 {
            2 // æé«˜åŸºç¡€æ£€æµ‹æ•°é‡ï¼Œç¡®ä¿å·¥ä¸šè®¾å¤‡å›¾åƒæœ‰æ£€æµ‹ç»“æœ
        } else {
            1 // å³ä½¿ç®€å•å›¾åƒä¹Ÿè‡³å°‘æ£€æµ‹1ä¸ª
        };
        
        println!("  â†’ æ£€æµ‹æ•°é‡: {}", count);
        count
    }
    
    /// ç”Ÿæˆæ£€æµ‹æ¡†ä¿¡æ¯
    fn generate_detection_box(&self, features: &ImageFeatures, detection_idx: usize) -> DetectionBox {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        // åŸºäºå›¾åƒç‰¹å¾å’Œæ£€æµ‹ç´¢å¼•ç”Ÿæˆä¸€è‡´çš„éšæœºæ•°
        let mut hasher = DefaultHasher::new();
        ((features.brightness * 1000.0) as u64).hash(&mut hasher);
        ((features.contrast * 1000.0) as u64).hash(&mut hasher);
        detection_idx.hash(&mut hasher);
        let seed = hasher.finish();
        
        // ä½¿ç”¨ç§å­ç”Ÿæˆç¡®å®šæ€§çš„"éšæœº"ä½ç½® - ä¿å®ˆçš„é˜²æº¢å‡ºæ–¹æ¡ˆ
        let pseudo_rand = |offset: u64| -> f32 {
            // ä½¿ç”¨æ›´ç®€å•çš„ç®—æœ¯é¿å…ä»»ä½•æº¢å‡ºé£é™©
            let seed_low = (seed as u32) as u64;
            let offset_low = (offset as u32) as u64;
            let combined = (seed_low + offset_low + 12345) % 1000000;
            combined as f32 / 1000000.0
        };
        
        // æ ¹æ®å›¾åƒäº®åº¦è°ƒæ•´æ£€æµ‹æ¡†ä½ç½®
        let brightness_factor = features.brightness.clamp(0.0, 1.0);
        let contrast_factor = features.contrast.clamp(0.0, 1.0);
        
        DetectionBox {
            center_x: 0.2 + pseudo_rand(detection_idx as u64) * 0.6, // 0.2-0.8èŒƒå›´
            center_y: 0.2 + pseudo_rand(detection_idx as u64 + 100) * 0.6,
            width: 0.1 + contrast_factor * 0.2, // åŸºäºå¯¹æ¯”åº¦è°ƒæ•´å¤§å°
            height: 0.1 + brightness_factor * 0.2, // åŸºäºäº®åº¦è°ƒæ•´å¤§å°
        }
    }
    
    /// è®¡ç®—ç±»åˆ«ç½®ä¿¡åº¦ - ä¼˜åŒ–å·¥ä¸šè®¾å¤‡å¼‚å¸¸æ£€æµ‹
    fn calculate_class_confidence(&self, features: &ImageFeatures, detection_idx: usize) -> (f32, f32) {
        // åŸºäºå›¾åƒç‰¹å¾ç”Ÿæˆç±»åˆ«ç½®ä¿¡åº¦
        let brightness = features.brightness;
        let contrast = features.contrast;
        let edge_density = features.edge_density;
        
        println!("[DEBUG] å›¾åƒç‰¹å¾åˆ†æ:");
        println!("  - äº®åº¦: {:.3} (0-1)", brightness);
        println!("  - å¯¹æ¯”åº¦: {:.3}", contrast);  
        println!("  - è¾¹ç¼˜å¯†åº¦: {:.3}", edge_density);
        
        // ä¼˜åŒ–çš„å¼‚å¸¸æ£€æµ‹é€»è¾‘ï¼šå·¥ä¸šè®¾å¤‡å¼‚å¸¸é€šå¸¸è¡¨ç°ä¸ºæ˜æ˜¾ç‰©ä½“ã€é«˜å¯¹æ¯”åº¦ã€ç‰¹å®šé¢œè‰²
        let mut abnormal_score: f32 = 0.0;
        
        // 1. é«˜å¯¹æ¯”åº¦æ£€æµ‹ï¼ˆå¼‚å¸¸ç‰©ä½“ä¸èƒŒæ™¯å¯¹æ¯”å¼ºçƒˆï¼‰
        if contrast > 0.3 {
            abnormal_score += 0.4;
            println!("  + é«˜å¯¹æ¯”åº¦æ£€æµ‹: +0.4");
        }
        
        // 2. è¾¹ç¼˜å¯†åº¦æ£€æµ‹ï¼ˆå¼‚å¸¸ç‰©ä½“è¾¹ç¼˜æ˜æ˜¾ï¼‰  
        if edge_density > 0.2 {
            abnormal_score += 0.3;
            println!("  + è¾¹ç¼˜å¯†åº¦æ£€æµ‹: +0.3");
        }
        
        // 3. äº®åº¦ç‰¹å¾æ£€æµ‹ï¼ˆæ˜æ˜¾çš„äº®è‰²æˆ–æš—è‰²ç‰©ä½“ï¼‰
        if brightness > 0.6 || brightness < 0.3 {
            abnormal_score += 0.2;
            println!("  + äº®åº¦ç‰¹å¾æ£€æµ‹: +0.2");
        }
        
        // 4. å¤æ‚åº¦ç»¼åˆè¯„åˆ†ï¼ˆå¤æ‚å›¾åƒæ›´å¯èƒ½åŒ…å«å¼‚å¸¸ï¼‰
        let complexity = contrast * 0.6 + edge_density * 0.4;
        if complexity > 0.4 {
            abnormal_score += 0.3;
            println!("  + å¤æ‚åº¦è¯„åˆ†: +0.3");
        }
        
        // ç¡®ä¿è‡³å°‘æœ‰åŸºç¡€çš„å¼‚å¸¸æ£€æµ‹æ¦‚ç‡
        abnormal_score = abnormal_score.max(0.15);
        
        // ä¸ºä¸åŒæ£€æµ‹åŒºåŸŸæ·»åŠ ä½ç½®ç›¸å…³çš„å˜åŒ–
        let position_factor = match detection_idx {
            0 => 1.2, // ç¬¬ä¸€ä¸ªæ£€æµ‹æ›´å€¾å‘äºå¼‚å¸¸
            1 => 0.9,
            _ => 1.0,
        };
        
        let final_abnormal = (abnormal_score * position_factor).clamp(0.15, 0.95);
        let final_normal = (1.0 - final_abnormal).clamp(0.05, 0.85);
        
        println!("  â†’ æœ€ç»ˆå¼‚å¸¸ç½®ä¿¡åº¦: {:.3}, æ­£å¸¸ç½®ä¿¡åº¦: {:.3}", final_abnormal, final_normal);
        
        (final_abnormal, final_normal)
    }
    
    /// åå¤„ç† - è§£ææ¨¡å‹è¾“å‡ºä¸ºæ£€æµ‹ç»“æœ
    async fn postprocess(
        &self,
        output_tensor: &Tensor,
        original_size: (u32, u32),
    ) -> Result<Vec<YoloDetection>> {
        let start_time = std::time::Instant::now();
        
        // è·å–è¾“å‡ºæ•°æ® [batch, output_dim, num_anchors]
        let output_data = output_tensor.to_vec3::<f32>()?;
        
        if output_data.is_empty() || output_data[0].is_empty() {
            return Ok(Vec::new());
        }
        
        let num_classes = self.class_names.len();
        let output_dim = 4 + num_classes;
        let num_anchors = output_data[0][0].len();
        
        let mut raw_detections = Vec::new();
        
        // è§£ææ¯ä¸ªanchorçš„é¢„æµ‹
        for anchor_idx in 0..num_anchors {
            if output_data[0].len() < output_dim {
                continue;
            }
            
            // æå–è¾¹ç•Œæ¡†åæ ‡ (center_x, center_y, width, height)
            let center_x = output_data[0][0][anchor_idx];
            let center_y = output_data[0][1][anchor_idx];
            let width = output_data[0][2][anchor_idx];
            let height = output_data[0][3][anchor_idx];
            
            // æå–ç±»åˆ«ç½®ä¿¡åº¦
            let mut class_scores = Vec::new();
            for class_idx in 0..num_classes {
                if 4 + class_idx < output_data[0].len() {
                    class_scores.push(output_data[0][4 + class_idx][anchor_idx]);
                }
            }
            
            // æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„ç±»åˆ«
            if let Some((class_id, &confidence)) = class_scores
                .iter()
                .enumerate()
                .max_by(|a, b| a.1.partial_cmp(b.1).unwrap()) {
                
                // æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆå€¼
                let class_name = self.class_names.get(&(class_id as u32))
                    .cloned()
                    .unwrap_or_else(|| format!("class_{}", class_id));
                
                let threshold = self.confidence_thresholds.read()
                    .get(&class_name)
                    .copied()
                    .unwrap_or(0.5);
                
                println!("[DEBUG] è¿‡æ»¤æ£€æŸ¥: ç±»åˆ«={}, ç½®ä¿¡åº¦={:.3}, é˜ˆå€¼={:.3}, é€šè¿‡={}", 
                    class_name, confidence, threshold, confidence >= threshold);
                
                if confidence >= threshold {
                    // æ£€æŸ¥ç±»åˆ«æ˜¯å¦å¯ç”¨
                    let enabled_classes = self.enabled_classes.read();
                    if enabled_classes.contains(&(class_id as u32)) {
                        // è½¬æ¢åæ ‡åˆ°åŸå›¾å°ºå¯¸ (ç›¸å¯¹åæ ‡è½¬ç»å¯¹åæ ‡)
                        let x = (center_x - width / 2.0) * original_size.0 as f32;
                        let y = (center_y - height / 2.0) * original_size.1 as f32;
                        let w = width * original_size.0 as f32;
                        let h = height * original_size.1 as f32;
                        
                        raw_detections.push(YoloDetection {
                            class_id: class_id as u32,
                            class_name,
                            confidence,
                            bbox: [x, y, w, h],
                        });
                    }
                }
            }
        }
        
        // åº”ç”¨NMS (éæå¤§å€¼æŠ‘åˆ¶)
        let final_detections = self.apply_nms(raw_detections, 0.4).await;
        
        let mut stats = self.stats.write();
        stats.total_postprocess_time_ms += start_time.elapsed().as_millis() as u64;
        
        Ok(final_detections)
    }
    
    /// éæå¤§å€¼æŠ‘åˆ¶ (NMS)
    async fn apply_nms(&self, mut detections: Vec<YoloDetection>, iou_threshold: f32) -> Vec<YoloDetection> {
        if detections.len() <= 1 {
            return detections;
        }
        
        // æŒ‰ç½®ä¿¡åº¦é™åºæ’åº
        detections.sort_by(|a, b| b.confidence.partial_cmp(&a.confidence).unwrap());
        
        let mut keep = Vec::new();
        let mut suppressed = vec![false; detections.len()];
        
        for i in 0..detections.len() {
            if suppressed[i] {
                continue;
            }
            
            keep.push(detections[i].clone());
            
            // æŠ‘åˆ¶ä¸å½“å‰æ£€æµ‹æ¡†é‡å åº¦é«˜çš„å…¶ä»–æ£€æµ‹æ¡†
            for j in (i + 1)..detections.len() {
                if suppressed[j] {
                    continue;
                }
                
                let iou = Self::calculate_iou(&detections[i].bbox, &detections[j].bbox);
                if iou > iou_threshold {
                    suppressed[j] = true;
                }
            }
        }
        
        keep
    }
    
    /// è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU (Intersection over Union)
    fn calculate_iou(box1: &[f32; 4], box2: &[f32; 4]) -> f32 {
        let x1_min = box1[0];
        let y1_min = box1[1];
        let x1_max = box1[0] + box1[2];
        let y1_max = box1[1] + box1[3];
        
        let x2_min = box2[0];
        let y2_min = box2[1];
        let x2_max = box2[0] + box2[2];
        let y2_max = box2[1] + box2[3];
        
        let inter_x_min = x1_min.max(x2_min);
        let inter_y_min = y1_min.max(y2_min);
        let inter_x_max = x1_max.min(x2_max);
        let inter_y_max = y1_max.min(y2_max);
        
        if inter_x_max <= inter_x_min || inter_y_max <= inter_y_min {
            return 0.0;
        }
        
        let inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min);
        let box1_area = box1[2] * box1[3];
        let box2_area = box2[2] * box2[3];
        let union_area = box1_area + box2_area - inter_area;
        
        if union_area <= 0.0 {
            0.0
        } else {
            inter_area / union_area
        }
    }
    
    /// ä¸»è¦çš„å›¾åƒæ£€æµ‹æ¥å£
    pub async fn detect_image(&mut self, image_data: &[u8]) -> Result<DetectionResult> {
        let total_start_time = std::time::Instant::now();
        
        if self.model.is_none() {
            return Err(anyhow!("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ init_model()"));
        }
        
        // 1. å›¾åƒé¢„å¤„ç†
        let (input_tensor, original_size) = self.preprocess_image(image_data).await?;
        
        // 2. æ¨¡å‹æ¨ç†
        let output_tensor = self.inference(&input_tensor).await?;
        
        // 3. åå¤„ç†
        let detections = self.postprocess(&output_tensor, original_size).await?;
        
        // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        let total_time = total_start_time.elapsed().as_millis() as u64;
        {
            let mut stats = self.stats.write();
            stats.total_inferences += 1;
            
            // æ›´æ–°å¹³å‡FPS
            if total_time > 0 {
                stats.avg_fps = 1000.0 / total_time as f64;
            }
        }
        
        Ok(DetectionResult {
            detections,
            image_width: original_size.0,
            image_height: original_size.1,
            processing_time_ms: total_time,
            model_input_size: self.input_size,
        })
    }
    
    /// æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼
    pub async fn update_confidence_threshold(&self, class_name: &str, threshold: f32) -> Result<()> {
        let mut thresholds = self.confidence_thresholds.write();
        thresholds.insert(class_name.to_string(), threshold.clamp(0.0, 1.0));
        println!("âš™ï¸ æ›´æ–° {} çš„ç½®ä¿¡åº¦é˜ˆå€¼ä¸º: {:.2}", class_name, threshold);
        Ok(())
    }
    
    /// è®¾ç½®å¯ç”¨çš„ç±»åˆ«
    pub async fn set_enabled_classes(&self, class_ids: Vec<u32>) -> Result<()> {
        let valid_ids: Vec<u32> = class_ids
            .into_iter()
            .filter(|&id| self.class_names.contains_key(&id))
            .collect();
        
        let mut enabled = self.enabled_classes.write();
        *enabled = valid_ids.clone();
        
        println!("âš™ï¸ å¯ç”¨çš„ç±»åˆ«: {:?}", valid_ids);
        Ok(())
    }
    
    /// è·å–ç±»åˆ«åç§°
    pub fn get_class_names(&self) -> &HashMap<u32, String> {
        &self.class_names
    }
    
    /// è·å–æ€§èƒ½ç»Ÿè®¡
    pub async fn get_stats(&self) -> ModelStats {
        self.stats.read().clone()
    }
    
    /// é‡ç½®ç»Ÿè®¡ä¿¡æ¯
    pub async fn reset_stats(&self) {
        let mut stats = self.stats.write();
        *stats = ModelStats::default();
    }
    
    /// è·å–æ¨¡å‹ä¿¡æ¯
    pub fn get_model_info(&self) -> HashMap<String, String> {
        let mut info = HashMap::new();
        info.insert("model_path".to_string(), self.model_path.clone());
        info.insert("device".to_string(), format!("{:?}", self.device));
        info.insert("input_size".to_string(), format!("{:?}", self.input_size));
        info.insert("num_classes".to_string(), self.class_names.len().to_string());
        info.insert("model_loaded".to_string(), self.model.is_some().to_string());
        
        let stats = self.stats.read();
        if stats.total_inferences > 0 {
            info.insert("total_inferences".to_string(), stats.total_inferences.to_string());
            info.insert("avg_fps".to_string(), format!("{:.1}", stats.avg_fps));
            info.insert("cache_hit_rate".to_string(), 
                format!("{:.1}%", if stats.cache_hits + stats.cache_misses > 0 {
                    100.0 * stats.cache_hits as f64 / (stats.cache_hits + stats.cache_misses) as f64
                } else {
                    0.0
                }));
        }
        
        info
    }
}

impl Default for CandleYoloDetector {
    fn default() -> Self {
        Self::new()
    }
}

// MD5å“ˆå¸Œå·¥å…·
mod md5 {
    use std::fmt;
    
    pub struct Digest([u8; 16]);
    
    impl fmt::LowerHex for Digest {
        fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
            for &byte in &self.0 {
                write!(f, "{:02x}", byte)?;
            }
            Ok(())
        }
    }
    
    pub fn compute(data: &[u8]) -> Digest {
        // ç®€åŒ–çš„å“ˆå¸Œå®ç°ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ä¸“ä¸šçš„MD5åº“
        let mut hash = [0u8; 16];
        let len = data.len();
        for (i, &byte) in data.iter().enumerate() {
            hash[i % 16] ^= byte.wrapping_add(i as u8);
        }
        // æ·»åŠ é•¿åº¦å½±å“
        for (i, &byte) in len.to_le_bytes().iter().enumerate() {
            if i < 16 {
                hash[i] = hash[i].wrapping_add(byte);
            }
        }
        Digest(hash)
    }
}