use anyhow::{Result, anyhow};
use candle_core::{Device, Tensor};
use image::{GenericImageView, DynamicImage};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::Path;
use std::sync::Arc;
use parking_lot::RwLock;
use tokio::sync::Mutex;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct YoloDetection {
    pub class_id: u32,
    pub class_name: String,
    pub confidence: f32,
    pub bbox: [f32; 4], // [x, y, width, height]
}

#[derive(Debug, Default, Clone)]
pub struct ModelStats {
    pub total_inferences: u64,
    pub total_preprocess_time_ms: u64,
    pub total_inference_time_ms: u64,
    pub total_postprocess_time_ms: u64,
    pub cache_hits: u64,
    pub cache_misses: u64,
    pub avg_fps: f64,
    pub memory_usage_mb: u64,
}

pub struct CandleYoloModel {
    device: Device,
    model_path: String,
    class_names: HashMap<u32, String>,
    input_size: (usize, usize),
    // æ€§èƒ½ä¼˜åŒ–ï¼šé¢„åˆ†é…å†…å­˜æ± 
    tensor_buffer: Arc<Mutex<Vec<f32>>>,
    // å›¾åƒå¤„ç†ç¼“å­˜
    image_cache: Arc<RwLock<Option<(Vec<u8>, (u32, u32), Vec<f32>)>>>, // (hash, size, tensor_data)
    // ç»Ÿè®¡ä¿¡æ¯
    stats: Arc<RwLock<ModelStats>>,
    // æ€§èƒ½ç›‘æ§
    last_inference_time: Arc<RwLock<std::time::Instant>>,
}

impl CandleYoloModel {
    pub fn new(model_path: &str) -> Result<Self> {
        // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆç”¨äºåŸºå‡†æµ‹è¯•æ—¶å¯ä»¥è·³è¿‡ï¼‰
        if !Path::new(model_path).exists() {
            println!("âš ï¸ Model file not found: {} (using simulation mode for benchmarking)", model_path);
        }

        // åˆå§‹åŒ–è®¾å¤‡ (ç›®å‰ä½¿ç”¨CPUï¼ŒGPUæ”¯æŒéœ€è¦æ›´å¤šé…ç½®)
        let device = Device::Cpu;
        println!("ğŸ’» Using CPU for inference (GPU support available with additional configuration)");
        
        // è®¾ç½®ç±»åˆ«åç§°ï¼ˆä» Box.yaml é…ç½®ï¼‰
        let mut class_names = HashMap::new();
        class_names.insert(0, "å¼‚å¸¸".to_string());
        class_names.insert(1, "æ­£å¸¸".to_string());

        // é¢„åˆ†é…å¼ é‡ç¼“å†²åŒº (640*640*3 = 1,228,800 floats â‰ˆ 4.9MB)
        let tensor_capacity = 640 * 640 * 3;
        let tensor_buffer = Arc::new(Mutex::new(Vec::with_capacity(tensor_capacity)));

        println!("ğŸ§  YOLO Model initialized with device: {:?}", device);

        Ok(Self {
            device,
            model_path: model_path.to_string(),
            class_names,
            input_size: (640, 640),
            tensor_buffer,
            image_cache: Arc::new(RwLock::new(None)),
            stats: Arc::new(RwLock::new(ModelStats::default())),
            last_inference_time: Arc::new(RwLock::new(std::time::Instant::now())),
        })
    }

    pub fn get_class_names(&self) -> &HashMap<u32, String> {
        &self.class_names
    }

    pub fn get_input_size(&self) -> (usize, usize) {
        self.input_size
    }

    // è®¡ç®—ç®€å•å“ˆå¸Œç”¨äºç¼“å­˜
    fn compute_hash(&self, data: &[u8]) -> Vec<u8> {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        data.hash(&mut hasher);
        let hash = hasher.finish();
        hash.to_le_bytes().to_vec()
    }

    // ä¼˜åŒ–çš„å›¾åƒé¢„å¤„ç†
    async fn preprocess_image_optimized(&self, image_data: &[u8]) -> Result<Tensor> {
        let start_time = std::time::Instant::now();
        
        // è®¡ç®—è¾“å…¥hashç”¨äºç¼“å­˜
        let image_hash = self.compute_hash(image_data);
        
        // æ£€æŸ¥ç¼“å­˜
        {
            let cache = self.image_cache.read();
            if let Some((cached_hash, _cached_size, ref tensor_data)) = cache.as_ref() {
                if *cached_hash == image_hash {
                    // ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜æ•°æ®
                    let mut stats = self.stats.write();
                    stats.cache_hits += 1;
                    stats.total_preprocess_time_ms += start_time.elapsed().as_millis() as u64;
                    
                    let tensor = Tensor::from_vec(
                        tensor_data.clone(),
                        &[1, 3, self.input_size.1, self.input_size.0],
                        &self.device,
                    )?;
                    return Ok(tensor);
                }
            }
        }
        
        // ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®é™…å¤„ç†
        let result = self.preprocess_image_internal(image_data, image_hash).await;
        
        let mut stats = self.stats.write();
        stats.cache_misses += 1;
        stats.total_preprocess_time_ms += start_time.elapsed().as_millis() as u64;
        
        result
    }

    async fn preprocess_image_internal(&self, image_data: &[u8], image_hash: Vec<u8>) -> Result<Tensor> {
        // é«˜æ•ˆå›¾åƒè§£ç å’Œè°ƒæ•´å¤§å°
        let img = image::load_from_memory(image_data)?;
        let (orig_width, orig_height) = img.dimensions();
        
        // ä½¿ç”¨æ›´å¿«çš„æ»¤æ³¢å™¨è¿›è¡Œresize
        let filter = if orig_width > self.input_size.0 as u32 * 2 {
            image::imageops::FilterType::Triangle // å¿«é€Ÿä¸‹é‡‡æ ·
        } else {
            image::imageops::FilterType::Lanczos3 // é«˜è´¨é‡
        };
        
        let resized = image::imageops::resize(
            &img.to_rgb8(),
            self.input_size.0 as u32,
            self.input_size.1 as u32,
            filter,
        );

        // ä½¿ç”¨é¢„åˆ†é…ç¼“å†²åŒºè¿›è¡Œé«˜æ•ˆå¼ é‡è½¬æ¢
        let mut tensor_buffer = self.tensor_buffer.lock().await;
        tensor_buffer.clear();
        tensor_buffer.reserve(3 * self.input_size.0 * self.input_size.1);
        
        // ä¼˜åŒ–çš„é€šé“åˆ†ç¦»å’Œå½’ä¸€åŒ–
        let pixels = resized.as_raw();
        let size = self.input_size.0 * self.input_size.1;
        
        // RGB -> CHW æ ¼å¼è½¬æ¢ï¼Œå¹¶è¡Œå¤„ç†é€šé“
        for c in 0..3 {
            for i in 0..size {
                let pixel_idx = i * 3 + c;
                let val = pixels[pixel_idx] as f32 * (1.0 / 255.0); // å¿«é€Ÿå½’ä¸€åŒ–
                tensor_buffer.push(val);
            }
        }
        
        let tensor_data = tensor_buffer.clone();

        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.image_cache.write();
            *cache = Some((image_hash, (orig_width, orig_height), tensor_data.clone()));
        }
        
        let tensor = Tensor::from_vec(
            tensor_data,
            &[1, 3, self.input_size.1, self.input_size.0],
            &self.device,
        )?;

        Ok(tensor)
    }

    // ä¼˜åŒ–çš„åå¤„ç†æ£€æµ‹ç»“æœ
    fn postprocess_detections_optimized(&self, output: &Tensor, confidence_threshold: f32) -> Result<Vec<YoloDetection>> {
        let start_time = std::time::Instant::now();

        // YOLOv8 è¾“å‡ºæ ¼å¼é€šå¸¸æ˜¯ [1, 84, 8400] å¯¹äº2ä¸ªç±»åˆ«
        // å…¶ä¸­ 84 = 4 (bbox) + 2 (classes)
        let output_data = output.to_vec2::<f32>()?;
        let mut detections = Vec::new();

        if output_data.is_empty() {
            return Ok(detections);
        }

        // ä¼˜åŒ–çš„æ£€æµ‹ç»“æœè§£æ
        let num_detections = output_data[0].len() / 6;
        detections.reserve(num_detections.min(100)); // é¢„åˆ†é…åˆç†çš„å®¹é‡
        
        for i in 0..num_detections {
            if i * 6 + 5 >= output_data[0].len() {
                break;
            }

            let x = output_data[0][i * 6];
            let y = output_data[0][i * 6 + 1];
            let w = output_data[0][i * 6 + 2];
            let h = output_data[0][i * 6 + 3];
            let conf_0 = output_data[0][i * 6 + 4]; // å¼‚å¸¸
            let conf_1 = output_data[0][i * 6 + 5]; // æ­£å¸¸

            // é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ç±»åˆ«
            let (class_id, confidence) = if conf_0 > conf_1 {
                (0, conf_0)
            } else {
                (1, conf_1)
            };

            // è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
            if confidence >= confidence_threshold {
                let class_name = self.class_names.get(&class_id)
                    .unwrap_or(&"æœªçŸ¥".to_string())
                    .clone();

                detections.push(YoloDetection {
                    class_id,
                    class_name,
                    confidence,
                    bbox: [x, y, w, h],
                });
            }
        }

        // NMS (Non-Maximum Suppression) ä¼˜åŒ–
        let filtered_detections = self.apply_nms(detections, 0.4);
        
        // æ›´æ–°ç»Ÿè®¡
        let mut stats = self.stats.write();
        stats.total_postprocess_time_ms += start_time.elapsed().as_millis() as u64;
        
        Ok(filtered_detections)
    }
    
    // ç®€åŒ–çš„NMSå®ç°
    fn apply_nms(&self, mut detections: Vec<YoloDetection>, iou_threshold: f32) -> Vec<YoloDetection> {
        if detections.len() <= 1 {
            return detections;
        }
        
        // æŒ‰ç½®ä¿¡åº¦æ’åº
        detections.sort_by(|a, b| b.confidence.partial_cmp(&a.confidence).unwrap());
        
        let mut result = Vec::new();
        let mut suppressed = vec![false; detections.len()];
        
        for i in 0..detections.len() {
            if suppressed[i] {
                continue;
            }
            
            result.push(detections[i].clone());
            
            // æŠ‘åˆ¶é‡å çš„æ£€æµ‹æ¡†
            for j in (i + 1)..detections.len() {
                if suppressed[j] {
                    continue;
                }
                
                let iou = self.calculate_iou(&detections[i].bbox, &detections[j].bbox);
                if iou > iou_threshold {
                    suppressed[j] = true;
                }
            }
        }
        
        result
    }
    
    // è®¡ç®—IoU (Intersection over Union)
    fn calculate_iou(&self, box1: &[f32; 4], box2: &[f32; 4]) -> f32 {
        let x1_min = box1[0];
        let y1_min = box1[1];
        let x1_max = box1[0] + box1[2];
        let y1_max = box1[1] + box1[3];
        
        let x2_min = box2[0];
        let y2_min = box2[1];
        let x2_max = box2[0] + box2[2];
        let y2_max = box2[1] + box2[3];
        
        let inter_x_min = x1_min.max(x2_min);
        let inter_y_min = y1_min.max(y2_min);
        let inter_x_max = x1_max.min(x2_max);
        let inter_y_max = y1_max.min(y2_max);
        
        if inter_x_max <= inter_x_min || inter_y_max <= inter_y_min {
            return 0.0;
        }
        
        let inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min);
        let box1_area = box1[2] * box1[3];
        let box2_area = box2[2] * box2[3];
        let union_area = box1_area + box2_area - inter_area;
        
        if union_area <= 0.0 {
            0.0
        } else {
            inter_area / union_area
        }
    }

    // å…¼å®¹åŸæœ‰æ¥å£
    fn preprocess_image(&self, image_data: &[u8]) -> Result<Tensor> {
        // åŒæ­¥ç‰ˆæœ¬ï¼Œç›´æ¥è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬å¹¶é˜»å¡ç­‰å¾…
        tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current().block_on(async {
                self.preprocess_image_optimized(image_data).await
            })
        })
    }

    fn postprocess_detections(&self, output: &Tensor, confidence_threshold: f32) -> Result<Vec<YoloDetection>> {
        self.postprocess_detections_optimized(output, confidence_threshold)
    }

    // ä¼˜åŒ–çš„å›¾åƒæ£€æµ‹æ–¹æ³•
    pub async fn detect_image(&self, image_data: &[u8]) -> Result<Vec<YoloDetection>> {
        let total_start_time = std::time::Instant::now();
        
        // æ›´æ–°ç»Ÿè®¡è®¡æ•°
        {
            let mut stats = self.stats.write();
            stats.total_inferences += 1;
        }

        // æ³¨æ„ï¼šç”±äºæˆ‘ä»¬ç›®å‰æœ‰ PyTorch æ¨¡å‹(.pt)ï¼Œä½† Candle éœ€è¦ç‰¹å®šæ ¼å¼
        // è¿™é‡Œå…ˆæä¾›ä¸€ä¸ªå¢å¼ºçš„æ¨¡æ‹Ÿå®ç°ï¼Œå¸¦æœ‰çœŸå®çš„å›¾åƒå¤„ç†
        
        // ä¼˜åŒ–çš„å›¾åƒé¢„å¤„ç†
        let _tensor = self.preprocess_image_optimized(image_data).await?;
        
        // TODO: å½“æœ‰ Candle æ ¼å¼æ¨¡å‹æ—¶ï¼Œæ›¿æ¢ä»¥ä¸‹æ¨¡æ‹Ÿé€»è¾‘
        // let inference_start = std::time::Instant::now();
        // let output = self.model.forward(&tensor)?;
        // let inference_time = inference_start.elapsed();
        // return self.postprocess_detections_optimized(&output, 0.5);

        // ä¸´æ—¶çš„å¢å¼ºæ¨¡æ‹Ÿ - åŸºäºçœŸå®å›¾åƒç‰¹å¾çš„æ™ºèƒ½æ£€æµ‹
        let img = image::load_from_memory(image_data)?;
        let (width, height) = img.dimensions();
        
        // æ›´æ™ºèƒ½çš„æ£€æµ‹é€»è¾‘ï¼šåˆ†æå›¾åƒç‰¹å¾
        let mut detections = Vec::new();
        
        // åŸºäºå›¾åƒå¤æ‚åº¦å’Œå°ºå¯¸çš„è‡ªé€‚åº”æ£€æµ‹
        let brightness = self.calculate_average_brightness(&img);
        let complexity_factor = (width * height) as f64 / (640.0 * 640.0);
        
        // æ¨¡æ‹Ÿä¸åŒåœºæ™¯çš„æ£€æµ‹ç»“æœ
        let num_objects = if complexity_factor > 2.0 { 
            3 // å¤§å›¾åƒå¯èƒ½æœ‰æ›´å¤šç›®æ ‡
        } else if brightness < 100.0 { 
            1 // æš—å›¾åƒæ£€æµ‹éš¾åº¦é«˜
        } else { 
            2 // æ ‡å‡†åœºæ™¯
        };
        
        for i in 0..num_objects {
            let class_id = if i % 2 == 0 { 1 } else { 0 }; // äº¤æ›¿æ­£å¸¸/å¼‚å¸¸
            
            // åŸºäºå›¾åƒç‰¹å¾çš„ç½®ä¿¡åº¦è®¡ç®—
            let base_confidence = if brightness > 150.0 { 0.85 } else { 0.65 };
            let confidence = base_confidence - (i as f32 * 0.05);
            
            // æ›´çœŸå®çš„è¾¹ç•Œæ¡†ä½ç½®
            let x = (width as f32 * 0.1) + (i as f32 * width as f32 * 0.25);
            let y = (height as f32 * 0.15) + (i as f32 * height as f32 * 0.2);
            let w = width as f32 * (0.15 + complexity_factor as f32 * 0.1);
            let h = height as f32 * (0.2 + complexity_factor as f32 * 0.05);

            let class_name = self.class_names.get(&class_id)
                .unwrap_or(&"æœªçŸ¥".to_string())
                .clone();

            detections.push(YoloDetection {
                class_id,
                class_name,
                confidence,
                bbox: [x, y, w, h],
            });
        }

        // æ›´æ–°æ€»æ¨ç†æ—¶é—´
        {
            let mut stats = self.stats.write();
            stats.total_inference_time_ms += total_start_time.elapsed().as_millis() as u64;
            
            // æ›´æ–°FPSç»Ÿè®¡
            let current_time = std::time::Instant::now();
            let mut last_time = self.last_inference_time.write();
            let time_diff = current_time.duration_since(*last_time).as_secs_f64();
            if time_diff > 0.0 {
                stats.avg_fps = 1.0 / time_diff;
            }
            *last_time = current_time;
        }
        
        Ok(detections)
    }

    // è®¡ç®—å›¾åƒå¹³å‡äº®åº¦ï¼ˆç”¨äºæ™ºèƒ½æ£€æµ‹ï¼‰
    fn calculate_average_brightness(&self, img: &DynamicImage) -> f32 {
        let rgb_img = img.to_rgb8();
        let pixels = rgb_img.as_raw();
        
        let mut total_brightness = 0u64;
        let num_pixels = pixels.len() / 3;
        
        for i in 0..num_pixels {
            let r = pixels[i * 3] as u64;
            let g = pixels[i * 3 + 1] as u64;
            let b = pixels[i * 3 + 2] as u64;
            // ä½¿ç”¨ç®€åŒ–çš„äº®åº¦è®¡ç®—å…¬å¼
            total_brightness += (r + g + b) / 3;
        }
        
        (total_brightness / num_pixels as u64) as f32
    }

    // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶çŠ¶æ€å’Œæ€§èƒ½ç»Ÿè®¡
    pub fn get_model_info(&self) -> HashMap<String, String> {
        let mut info = HashMap::new();
        info.insert("model_path".to_string(), self.model_path.clone());
        info.insert("device".to_string(), format!("{:?}", self.device));
        info.insert("input_size".to_string(), format!("{:?}", self.input_size));
        info.insert("num_classes".to_string(), self.class_names.len().to_string());
        
        // æ·»åŠ æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
        let stats = self.stats.read();
        if stats.total_inferences > 0 {
            let avg_inference_time = stats.total_inference_time_ms / stats.total_inferences;
            let avg_preprocess_time = stats.total_preprocess_time_ms / stats.total_inferences;
            let avg_postprocess_time = stats.total_postprocess_time_ms / stats.total_inferences;
            let cache_hit_rate = if stats.cache_hits + stats.cache_misses > 0 {
                (stats.cache_hits as f64 / (stats.cache_hits + stats.cache_misses) as f64 * 100.0) as u64
            } else {
                0
            };
            
            info.insert("total_inferences".to_string(), stats.total_inferences.to_string());
            info.insert("avg_inference_time_ms".to_string(), avg_inference_time.to_string());
            info.insert("avg_preprocess_time_ms".to_string(), avg_preprocess_time.to_string());
            info.insert("avg_postprocess_time_ms".to_string(), avg_postprocess_time.to_string());
            info.insert("cache_hit_rate_percent".to_string(), cache_hit_rate.to_string());
            info.insert("avg_fps".to_string(), format!("{:.1}", stats.avg_fps));
        }
        
        info
    }
    
    // è·å–æ€§èƒ½ç»Ÿè®¡
    pub async fn get_performance_stats(&self) -> ModelStats {
        self.stats.read().clone()
    }
    
    // é‡ç½®ç»Ÿè®¡ä¿¡æ¯
    pub async fn reset_stats(&self) {
        let mut stats = self.stats.write();
        *stats = ModelStats::default();
    }
    
    // æ¸…é™¤ç¼“å­˜
    pub async fn clear_cache(&self) {
        let mut cache = self.image_cache.write();
        *cache = None;
        
        // æ¸…é™¤å¼ é‡ç¼“å†²åŒº
        let mut buffer = self.tensor_buffer.lock().await;
        buffer.clear();
        buffer.shrink_to_fit();
    }

    // å†…å­˜ä½¿ç”¨ç›‘æ§
    pub async fn get_memory_usage(&self) -> u64 {
        let buffer = self.tensor_buffer.lock().await;
        let cache = self.image_cache.read();
        
        let mut total_bytes = buffer.capacity() * std::mem::size_of::<f32>();
        
        if let Some((_, _, ref tensor_data)) = cache.as_ref() {
            total_bytes += tensor_data.capacity() * std::mem::size_of::<f32>();
        }
        
        (total_bytes / 1024 / 1024) as u64 // è½¬æ¢ä¸ºMB
    }

    // æ€§èƒ½åˆ†ææŠ¥å‘Š
    pub async fn generate_performance_report(&self) -> String {
        let stats = self.stats.read();
        let memory_usage = self.get_memory_usage().await;
        
        format!(
            "ğŸ”¥ YOLO Performance Report\n\
            ================================\n\
            ğŸ“Š Inference Statistics:\n\
            â€¢ Total Inferences: {}\n\
            â€¢ Average FPS: {:.1}\n\
            â€¢ Avg Inference Time: {}ms\n\
            â€¢ Avg Preprocess Time: {}ms\n\
            â€¢ Avg Postprocess Time: {}ms\n\
            \n\
            ğŸ’¾ Memory & Cache:\n\
            â€¢ Memory Usage: {}MB\n\
            â€¢ Cache Hit Rate: {:.1}%\n\
            â€¢ Cache Hits: {}\n\
            â€¢ Cache Misses: {}\n\
            \n\
            ğŸš€ Device Info:\n\
            â€¢ Device: {:?}\n\
            â€¢ Input Size: {:?}\n\
            â€¢ Model Path: {}",
            stats.total_inferences,
            stats.avg_fps,
            if stats.total_inferences > 0 { stats.total_inference_time_ms / stats.total_inferences } else { 0 },
            if stats.total_inferences > 0 { stats.total_preprocess_time_ms / stats.total_inferences } else { 0 },
            if stats.total_inferences > 0 { stats.total_postprocess_time_ms / stats.total_inferences } else { 0 },
            memory_usage,
            if stats.cache_hits + stats.cache_misses > 0 { 
                stats.cache_hits as f64 / (stats.cache_hits + stats.cache_misses) as f64 * 100.0 
            } else { 0.0 },
            stats.cache_hits,
            stats.cache_misses,
            self.device,
            self.input_size,
            self.model_path
        )
    }
}

// ç½®ä¿¡åº¦é˜ˆå€¼ç®¡ç†
pub struct ConfidenceThresholds {
    thresholds: Arc<RwLock<HashMap<String, f32>>>,
}

impl ConfidenceThresholds {
    pub fn new() -> Self {
        let mut thresholds = HashMap::new();
        thresholds.insert("å¼‚å¸¸".to_string(), 0.7); // å¼‚å¸¸æ£€æµ‹é˜ˆå€¼ç¨é«˜
        thresholds.insert("æ­£å¸¸".to_string(), 0.5);
        
        Self {
            thresholds: Arc::new(RwLock::new(thresholds)),
        }
    }

    pub async fn update_threshold(&self, class_name: &str, threshold: f32) {
        let mut thresholds = self.thresholds.write();
        thresholds.insert(class_name.to_string(), threshold);
    }

    pub async fn get_threshold(&self, class_name: &str) -> f32 {
        let thresholds = self.thresholds.read();
        thresholds.get(class_name).copied().unwrap_or(0.5)
    }

    pub async fn get_all_thresholds(&self) -> HashMap<String, f32> {
        let thresholds = self.thresholds.read();
        thresholds.clone()
    }
}