use anyhow::{Context, Result};
use opencv::{core, imgcodecs, imgproc, prelude::*, videoio};
use serde::{Deserialize, Serialize};
use std::path::Path;
use std::sync::Arc;
use tokio::sync::RwLock;

use super::{YoloDetection, YoloModel, ConfidenceThresholds};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum InputSource {
    Camera { device_id: i32 },
    Video { path: String },
    Image { path: String },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionResult {
    pub detections: Vec<YoloDetection>,
    pub frame_data: Option<String>, // base64编码的图像数据
    pub timestamp: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionState {
    pub is_running: bool,
    pub current_source: Option<InputSource>,
    pub results: Vec<DetectionResult>,
    pub selected_classes: Vec<u32>,
}

pub struct YoloDetectionEngine {
    model: Arc<YoloModel>,
    thresholds: Arc<ConfidenceThresholds>,
    state: Arc<RwLock<DetectionState>>,
    camera: Arc<RwLock<Option<videoio::VideoCapture>>>,
}

impl YoloDetectionEngine {
    pub fn new(model_path: &str) -> Result<Self> {
        let model = Arc::new(YoloModel::new(model_path)?);
        let thresholds = Arc::new(ConfidenceThresholds::new());
        
        let initial_state = DetectionState {
            is_running: false,
            current_source: None,
            results: Vec::new(),
            selected_classes: vec![0, 1], // 默认选择所有类别
        };

        Ok(Self {
            model,
            thresholds,
            state: Arc::new(RwLock::new(initial_state)),
            camera: Arc::new(RwLock::new(None)),
        })
    }

    pub async fn start_camera(&self, device_id: i32) -> Result<()> {
        // 初始化摄像头
        let mut camera = videoio::VideoCapture::new(device_id, videoio::CAP_ANY)
            .context("Failed to open camera")?;
        
        if !camera.is_opened()? {
            return Err(anyhow::anyhow!("Camera is not opened"));
        }

        // 设置摄像头参数
        camera.set(videoio::CAP_PROP_FRAME_WIDTH, 640.0)?;
        camera.set(videoio::CAP_PROP_FRAME_HEIGHT, 480.0)?;
        camera.set(videoio::CAP_PROP_FPS, 30.0)?;

        // 更新状态
        {
            let mut state = self.state.write().await;
            state.current_source = Some(InputSource::Camera { device_id });
            state.is_running = true;
        }

        // 存储摄像头实例
        *self.camera.write().await = Some(camera);

        Ok(())
    }

    pub async fn start_video(&self, video_path: &str) -> Result<()> {
        // 检查文件是否存在
        if !Path::new(video_path).exists() {
            return Err(anyhow::anyhow!("Video file does not exist: {}", video_path));
        }

        // 打开视频文件
        let camera = videoio::VideoCapture::from_file(video_path, videoio::CAP_ANY)
            .context("Failed to open video file")?;

        if !camera.is_opened()? {
            return Err(anyhow::anyhow!("Video file cannot be opened"));
        }

        // 更新状态
        {
            let mut state = self.state.write().await;
            state.current_source = Some(InputSource::Video { path: video_path.to_string() });
            state.is_running = true;
        }

        // 存储视频捕获实例
        *self.camera.write().await = Some(camera);

        Ok(())
    }

    pub async fn process_image(&self, image_path: &str) -> Result<DetectionResult> {
        // 检查文件是否存在
        if !Path::new(image_path).exists() {
            return Err(anyhow::anyhow!("Image file does not exist: {}", image_path));
        }

        // 读取图像文件
        let image_data = tokio::fs::read(image_path).await
            .context("Failed to read image file")?;

        // 运行检测
        let detections = self.model.detect_image(&image_data).await?;

        // 过滤检测结果
        let filtered_detections = self.filter_detections(detections).await;

        // 读取图像用于绘制结果
        let mut img = imgcodecs::imread(image_path, imgcodecs::IMREAD_COLOR)?;
        
        // 绘制检测结果
        self.draw_detections(&mut img, &filtered_detections)?;

        // 转换为base64
        let mut buf = core::Vector::new();
        imgcodecs::imencode(".jpg", &img, &mut buf, &core::Vector::new())?;
        let image_base64 = base64::encode(buf.as_slice());

        // 更新状态
        {
            let mut state = self.state.write().await;
            state.current_source = Some(InputSource::Image { path: image_path.to_string() });
        }

        Ok(DetectionResult {
            detections: filtered_detections,
            frame_data: Some(image_base64),
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64,
        })
    }

    pub async fn get_next_frame(&self) -> Result<Option<DetectionResult>> {
        let mut camera_lock = self.camera.write().await;
        let camera = match camera_lock.as_mut() {
            Some(cam) => cam,
            None => return Ok(None),
        };

        let mut frame = core::Mat::default();
        let ret = camera.read(&mut frame)?;

        if !ret || frame.empty() {
            // 如果是视频文件，重新开始
            let state = self.state.read().await;
            if let Some(InputSource::Video { path }) = &state.current_source {
                let video_path = path.clone();
                drop(state);
                drop(camera_lock);
                
                // 重新打开视频
                self.start_video(&video_path).await?;
                return self.get_next_frame().await;
            }
            return Ok(None);
        }

        // 将OpenCV Mat转换为图像数据
        let mut buf = core::Vector::new();
        imgcodecs::imencode(".jpg", &frame, &mut buf, &core::Vector::new())?;
        let image_data = buf.to_vec();

        // 运行检测
        let detections = self.model.detect_image(&image_data).await?;

        // 过滤检测结果
        let filtered_detections = self.filter_detections(detections).await;

        // 绘制检测结果
        let mut annotated_frame = frame.clone();
        self.draw_detections(&mut annotated_frame, &filtered_detections)?;

        // 转换为base64
        let mut result_buf = core::Vector::new();
        imgcodecs::imencode(".jpg", &annotated_frame, &mut result_buf, &core::Vector::new())?;
        let frame_base64 = base64::encode(result_buf.as_slice());

        Ok(Some(DetectionResult {
            detections: filtered_detections,
            frame_data: Some(frame_base64),
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64,
        }))
    }

    pub async fn stop_detection(&self) -> Result<()> {
        {
            let mut state = self.state.write().await;
            state.is_running = false;
            state.current_source = None;
        }

        *self.camera.write().await = None;
        Ok(())
    }

    pub async fn update_confidence_threshold(&self, class_name: &str, threshold: f32) -> Result<()> {
        self.thresholds.update_threshold(class_name, threshold).await;
        Ok(())
    }

    pub async fn get_detection_state(&self) -> DetectionState {
        self.state.read().await.clone()
    }

    pub async fn set_selected_classes(&self, class_ids: Vec<u32>) -> Result<()> {
        let mut state = self.state.write().await;
        state.selected_classes = class_ids;
        Ok(())
    }

    async fn filter_detections(&self, detections: Vec<YoloDetection>) -> Vec<YoloDetection> {
        let state = self.state.read().await;
        let mut filtered = Vec::new();

        for detection in detections {
            // 检查类别是否被选中
            if !state.selected_classes.contains(&detection.class_id) {
                continue;
            }

            // 检查置信度阈值
            let threshold = self.thresholds.get_threshold(&detection.class_name).await;
            if detection.confidence >= threshold {
                filtered.push(detection);
            }
        }

        filtered
    }

    fn draw_detections(&self, img: &mut core::Mat, detections: &[YoloDetection]) -> Result<()> {
        for detection in detections {
            let [x, y, w, h] = detection.bbox;
            
            // 绘制边界框
            let rect = core::Rect::new(x as i32, y as i32, w as i32, h as i32);
            let color = match detection.class_id {
                0 => core::Scalar::new(0.0, 0.0, 255.0, 0.0), // 红色（异常）
                1 => core::Scalar::new(0.0, 255.0, 0.0, 0.0), // 绿色（正常）
                _ => core::Scalar::new(255.0, 0.0, 0.0, 0.0),  // 蓝色（其他）
            };
            
            imgproc::rectangle(img, rect, color, 2, imgproc::LINE_8, 0)?;
            
            // 绘制标签
            let label = format!("{}: {:.2}", detection.class_name, detection.confidence);
            let text_size = imgproc::get_text_size(&label, imgproc::FONT_HERSHEY_SIMPLEX, 0.6, 1, &mut 0)?;
            
            let text_pos = core::Point::new(x as i32, y as i32 - 10);
            let text_bg = core::Rect::new(
                x as i32, 
                y as i32 - text_size.height - 10, 
                text_size.width, 
                text_size.height + 5
            );
            
            imgproc::rectangle(img, text_bg, color, -1, imgproc::LINE_8, 0)?;
            imgproc::put_text(
                img,
                &label,
                text_pos,
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.6,
                core::Scalar::new(255.0, 255.0, 255.0, 0.0),
                1,
                imgproc::LINE_8,
                false,
            )?;
        }
        
        Ok(())
    }
}